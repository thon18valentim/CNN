{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "BtdLiZBwKcyh",
        "-AjMnaikIWE5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "BtdLiZBwKcyh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93BZYA0bYtzw",
        "outputId": "3531f85a-e5eb-4244-ffe0-550fbe9dd310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Input, MaxPooling2D, GlobalAveragePooling2D, Dense, MaxPool2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import ReLU, GlobalAvgPool2D, Dropout\n",
        "from PIL import Image\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the testing images and the training images. Each images pass through a resize and normalization function."
      ],
      "metadata": {
        "id": "pGQWBBCkabNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lidando com as Imagens"
      ],
      "metadata": {
        "id": "-AjMnaikIWE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagesTesting = []\n",
        "labelsTesting = []\n",
        "imagesTraining = []\n",
        "labelsTraining = []\n",
        "classLabels = ['barberry', 'bayberry', 'beach plum', 'bearberry', 'black berry',\n",
        "               'black cherry', 'blueberry', 'ceylon gooseberry', 'chokeberry', 'crowberry']\n",
        "\n",
        "target_size = (224, 224)\n",
        "\n",
        "def readTestingImages():\n",
        "    os.chdir('/content/drive/MyDrive/CNN_SOURCE/Testing/Testing')\n",
        "\n",
        "    imageCountList = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "    for filename in os.listdir():\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            # Read Image\n",
        "            image = cv2.imread(filename)\n",
        "\n",
        "            # Resize the image\n",
        "            image_resized = cv2.resize(image, target_size)\n",
        "\n",
        "            # Normalize the image\n",
        "            image_normalized = image_resized / 255.0\n",
        "\n",
        "            # Extract label from filename\n",
        "            labels = filename.rsplit(\"_\", 1)\n",
        "            label = labels[0].replace('_', ' ')\n",
        "\n",
        "            # Get the index of the label in classLabels\n",
        "            label_index = classLabels.index(label)\n",
        "            imageCountList[label_index] += 1\n",
        "\n",
        "            if imageCountList[label_index] > 150:\n",
        "              continue\n",
        "\n",
        "            imagesTesting.append(image_normalized)\n",
        "            labelsTesting.append(label_index)\n",
        "\n",
        "def readTrainingImages():\n",
        "    os.chdir('/content/drive/MyDrive/CNN_SOURCE/Training/Training')\n",
        "\n",
        "    imageCountList = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "    for filename in os.listdir():\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            # Read Image\n",
        "            image = cv2.imread(filename)\n",
        "\n",
        "            # Resize the image\n",
        "            image_resized = cv2.resize(image, target_size)\n",
        "\n",
        "            # Normalize the image\n",
        "            image_normalized = image_resized / 255.0\n",
        "\n",
        "            # Extract label from filename\n",
        "            labels = filename.rsplit(\"_\", 1)\n",
        "            label = labels[0].replace('_', ' ')\n",
        "\n",
        "            # Get the index of the label in classLabels\n",
        "            label_index = classLabels.index(label)\n",
        "            imageCountList[label_index] += 1\n",
        "\n",
        "            if imageCountList[label_index] > 600:\n",
        "              continue\n",
        "\n",
        "            imagesTraining.append(image_normalized)\n",
        "            labelsTraining.append(label_index)\n",
        "\n",
        "readTestingImages()\n",
        "readTrainingImages()"
      ],
      "metadata": {
        "id": "-oDqT_Y4aSDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the CNN architecture\n",
        "\n",
        "We start with a architecture of 7 layers. 2 are convolutional layers. 2 are max-pooling layers, a layer to flatten the previous output into a 1D vector, and 2 connected layers (dense layers).\n",
        "\n",
        "**model = models.Sequential()**: this creates a sequential model, which is a linear stack of layers\n",
        "\n",
        "**model.add(layers.Vonc2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))**: adds a 2D convolutional layer to the model with 32 filters. The number of filters determine the number of channels of the output feature maps. Each filter produces one feature map, and these feature maps collectively capture different aspects of the input data.\n",
        "\n",
        "**model.add(layers.MaxPooling2D((2, 2)))**: adds a max-pooling layer to the model with a pool size of 2x2. Max-pooling reduces the spatial dimensions of the feature maps.\n",
        "\n",
        "**model.add(layers.Flatten())**: this flattens the output of the previous layer into a 1D vector. This reshapes the multi-dimensional feature maps into a 1D vector that can be fed into the fully connected layer. Each element in the vector corresponds to a specific feature or activation in the feature map.\n",
        "\n",
        "**model.add(layers.Dense(64, activation='relu'))**: This adds a fully connected (dense) layer with 64 units and the ReLU activation function.\n",
        "\n",
        "**model.add(layers.Dense(10))**: This adds the final fully connected layer with 10 units. Since this is a classification problem with 10 classes, this layer will produce the output logits for each class."
      ],
      "metadata": {
        "id": "Xy_jTymkhLOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitetura Resnet"
      ],
      "metadata": {
        "id": "6PT1qV-AIbEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_convulational_layer(x, f, k=1, s=1, p='same'):\n",
        "    x = Conv2D(f, k, strides=s, padding=p)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return MaxPool2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "def identity_block(tensor, f):\n",
        "    x = create_convulational_layer(tensor, f)\n",
        "    x = create_convulational_layer(x, f, 3)\n",
        "    x = Conv2D(4*f, 1)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, tensor])\n",
        "    output = ReLU()(x)\n",
        "    return output\n",
        "\n",
        "def conv_block(tensor, f, s):\n",
        "  x = create_convulational_layer(tensor, f)\n",
        "  x = create_convulational_layer(x, f, 3, s)\n",
        "  x = Conv2D(4*f, 1)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  shortcut = Conv2D(4*f, 1, strides=s)(tensor)\n",
        "  shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "  x = Add()([x, shortcut])\n",
        "  output = ReLU()(x)\n",
        "  return output\n",
        "\n",
        "def create_resnet_block(x, f, r, s=2):\n",
        "  x = conv_block(x, f, s)\n",
        "  for _ in range(r-1):\n",
        "    x = identity_block(x, f)\n",
        "  return x\n",
        "\n",
        "def build_resnet(input_shape, num_classes):\n",
        "  input = Input(input_shape)\n",
        "\n",
        "  # Primeira camada convolucional adicional\n",
        "  x = create_convulational_layer(input, 64, 3, 2)\n",
        "\n",
        "  # Segunda camada convolucional adicional\n",
        "  x = create_convulational_layer(x, 64, 3, 1)\n",
        "\n",
        "  # Terceira camada convolucional adicional\n",
        "  x = create_convulational_layer(x, 64, 3, 1)\n",
        "\n",
        "  # Quarta camada convolucional adicional\n",
        "  x = create_convulational_layer(x, 64, 3, 1)\n",
        "\n",
        "  # Quinta camada convolucional adicional\n",
        "  x = create_convulational_layer(x, 64, 3, 1)\n",
        "\n",
        "  # Sexta camada convolucional adicional\n",
        "  x = create_convulational_layer(x, 64, 3, 1)\n",
        "\n",
        "  x = create_resnet_block(x, 64, 3, 1)\n",
        "  x = create_resnet_block(x, 128, 4)\n",
        "  x = create_resnet_block(x, 256, 6)\n",
        "  x = create_resnet_block(x, 512, 3)\n",
        "\n",
        "  x = GlobalAvgPool2D()(x)\n",
        "\n",
        "  x = Dropout(0.5)(x)\n",
        "\n",
        "  output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  model = Model(input, output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "hZjmPaxA232q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construindo Modelo"
      ],
      "metadata": {
        "id": "fownbo8Njocp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar os dados de entrada para o formato esperado pela rede\n",
        "imagesTraining = np.array(imagesTraining).astype('float32')\n",
        "imagesTesting = np.array(imagesTesting).astype('float32')\n",
        "imagesTraining /= 255.0\n",
        "imagesTesting /= 255.0\n",
        "\n",
        "# Definir o número de classes do problema\n",
        "num_classes = 10\n",
        "\n",
        "labelsTraining = np.array(labelsTraining)\n",
        "labelsTraining = to_categorical(labelsTraining, num_classes)\n",
        "labelsTesting = np.array(labelsTesting)\n",
        "labelsTesting = to_categorical(labelsTesting, num_classes)\n",
        "\n",
        "# Construir o modelo ResNet\n",
        "input_shape = imagesTraining[0].shape\n",
        "model = build_resnet(input_shape, num_classes)"
      ],
      "metadata": {
        "id": "byy3tUVN29VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinando Modelo"
      ],
      "metadata": {
        "id": "AVvhGAl1KVkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar o modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(imagesTraining, labelsTraining, batch_size=32, epochs=50, validation_data=(imagesTesting, labelsTesting))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCB2fKID5lX6",
        "outputId": "1a531a9f-3dd1-483e-989c-5d7b8112e2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.7929 - accuracy: 0.1975 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação do Modelo"
      ],
      "metadata": {
        "id": "L6Ny0QuW6ogY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação do modelo\n",
        "test_loss, test_acc = model.evaluate(imagesTesting, labelsTesting)\n",
        "print('Acurácia final do modelo: %.2f%%' % (test_acc * 100))"
      ],
      "metadata": {
        "id": "mvlUzRpqlb11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.05, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "vUT_636G5Go_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim([0.1, 30])\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "MSt_hlal61UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvando Modelo"
      ],
      "metadata": {
        "id": "BedXIqGH4s7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o modelo\n",
        "model.save('/content/drive/MyDrive/CNN_SOURCE/Modelos/cnn_modelo_resnet.h5')"
      ],
      "metadata": {
        "id": "2HG-Up6iITkp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}